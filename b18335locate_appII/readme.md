学习材料：

https://dormousehole.readthedocs.io/en/latest/
flask 框架
https://www.numpy.org.cn/
NumPy官方的中文文档
http://www.pypandas.cn/
pandas中文文档


--------------------------------------------------------
部署流程：

ubuntu(我是在ubuntu 18.04）或者其他linux，或者osx等类unix系统
其他系统没有经过充分测试

1.
安装python3.6 以上版本

2. 
安装pip3 

3.
（可选，非必须）（创建python3虚拟目录，隔绝不同版本库之间相互影响）
https://docs.python.org/zh-cn/3/tutorial/venv.html


4.
terminal底下进入工程目录下，在requirements.txt同级目录下运行：
pip3 install --upgrade -r requirements.txt


5.
运行已经训练好的结果看, 在terminal输入：
python3 i2visual_and_analysis.py
查看可视化和规律

python3 i3rssi_to_predict.py
运行后，按ctrl+z终止，查看模拟识别


# 架构部分
− 训练数据预处理。我们对数据集进行数据探索，前 提假设是:用户在短时间的行走中不可能跨越太长的距离，信号也不会产生巨大 的跳跃，应该是比较平滑的衰减。这种使用聚类方法把对不同hub的数据特征进行自分类，能够有效地剔除噪声数据，提高定位的精度。 
我们对整体数据进行训练：进行监督式机器学习KNN。如果k太小了，比如等于1，那么模型就太复杂了，我们很容易学习到噪声，
也就非常容易判定为噪声类别，而对于我们的问题，我们可以非常好的预判出K的数值：我们先对信号特征找到最接近，信号规律最有特点的hub的作用域，所以k选取hub的个数。
KNN(K-Nearest Neighbor)是最简单的机器学习算法之一，可以用于分类和回归，
是一种监督学习算法。它的思路是这样，如果一个样本在特征空间中的K个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。也就是说，该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。
一般来说，KNN分类算法的计算过程：
1）计算待分类点与已知类别的点之间的距离
2）按照距离递增次序排序
3）选取与待分类点距离最小的K个点
4）确定前K个点所在类别的出现次数
5）返回前K个点出现次数最高的类别作为待分类点的预测分类
	准备测试数据。测试数据是未标定的用户轨迹信号序列（已知地址），
	将无法探测到的信号填充为最小值。然后我们对其在系统进行测试。

具体过程是一种基于分类國值及信号强度权重的室内定位方法，其特征在于包括以下步骤：
1）将目标区域划分成均匀网格，在各网格中心点测量接收到的各信标节点的 RSSI 值，
构建 PSSI 指纹地图；
2）根据各参考点采集的平均信号强度与距离之间的关系对所有参考点分类；
3） 利用步骤2）的分类结果，分别确定各参考点的匹配國值；
4） 在移动节点的定位阶段中，根据实时 RSSI值以及各类参考点國值，从RSSI 指纹地图
投票选出优选参考点：
5）以优选参考点的信号强度作为权重,采用加权K邻近定位算法估算出移动节点的位
置；

